{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "febfd6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to Python path\n",
    "parent_dir = Path().resolve().parent\n",
    "sys.path.insert(0, str(parent_dir))\n",
    "\n",
    "from model.model_loader import ModelLoader\n",
    "from data.data_loader import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d22b52",
   "metadata": {},
   "source": [
    "## Load Model\n",
    "Initialize the model loader and load the pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f17c113d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config from C:\\Users\\Besitzer\\OneDrive\\Dokumente\\CBS_Copenhagen\\Semester\\WS2025\\AdvNLP\\Final Exam\\AVDNLP_final_project\\configs\\config.yaml\n",
      "Transformer frozen - only training classification heads\n",
      "Unfroze top 2 layers (out of 6)\n",
      "Model loaded successfully on cpu\n",
      "Model type: <class 'model.model_loader.MultiTaskClassifier'>\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model_loader = ModelLoader()\n",
    "model,tokenizer = model_loader.load_model_and_tokenizer(freeze_strategy='partial-2', use_lora=False)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded successfully on {device}\")\n",
    "print(f\"Model type: {type(model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7356409b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total parameters: 66,367,494\n",
      "Trainable parameters: 14,180,358\n",
      "Frozen parameters: 52,187,136\n",
      "Trainable percentage: 21.37%\n"
     ]
    }
   ],
   "source": [
    "# Summary of trainable vs frozen parameters\n",
    "total, trainable = model_loader.count_parameters(model)\n",
    "print(f\"\\nTotal parameters: {total:,}\")\n",
    "print(f\"Trainable parameters: {trainable:,}\")\n",
    "print(f\"Frozen parameters: {total - trainable:,}\")\n",
    "print(f\"Trainable percentage: {100 * trainable / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24b9eeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiTaskClassifier(\n",
      "  (transformer): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): DistilBertSdpaAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (direction_head): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (comparison_head): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (future_info_head): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97b26385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config from C:\\Users\\Besitzer\\OneDrive\\Dokumente\\CBS_Copenhagen\\Semester\\WS2025\\AdvNLP\\Final Exam\\AVDNLP_final_project\\configs\\config.yaml\n",
      "Loaded: C:\\Users\\Besitzer\\OneDrive\\Dokumente\\CBS_Copenhagen\\Semester\\WS2025\\AdvNLP\\Final Exam\\AVDNLP_final_project\\data\\processed_data.csv\n"
     ]
    }
   ],
   "source": [
    "# prepare data for a small test\n",
    "data_loader = DataLoader()\n",
    "sample_data = data_loader.load_sample_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9a47288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>price_direction_up</th>\n",
       "      <th>price_direction_constant</th>\n",
       "      <th>price_direction_down</th>\n",
       "      <th>asset_comparision</th>\n",
       "      <th>past_information</th>\n",
       "      <th>future_information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gold futures climb; metals stocks narrowly higher</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gold futures hit fresh high in electronic trading</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gold prices up as stock market falters</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gold turns slightly positive after consumer-pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gold prices end modestly higher after three se...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news  price_direction_up  \\\n",
       "0  gold futures climb; metals stocks narrowly higher                   1   \n",
       "1  gold futures hit fresh high in electronic trading                   1   \n",
       "2             gold prices up as stock market falters                   1   \n",
       "3  Gold turns slightly positive after consumer-pr...                   1   \n",
       "4  Gold prices end modestly higher after three se...                   1   \n",
       "\n",
       "   price_direction_constant  price_direction_down  asset_comparision  \\\n",
       "0                         0                     0                  0   \n",
       "1                         0                     0                  0   \n",
       "2                         0                     0                  0   \n",
       "3                         0                     0                  0   \n",
       "4                         0                     0                  0   \n",
       "\n",
       "   past_information  future_information  \n",
       "0                 1                   0  \n",
       "1                 1                   0  \n",
       "2                 1                   0  \n",
       "3                 1                   0  \n",
       "4                 1                   0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aa1efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample predictions:\n",
      "Direction: tensor([[ 0.2023,  0.1824],\n",
      "        [ 0.0477, -0.0041],\n",
      "        [ 0.1233, -0.0630]])\n",
      "Comparison: tensor([[ 0.0855, -0.0068],\n",
      "        [ 0.0087, -0.0705],\n",
      "        [ 0.1297, -0.0631]])\n",
      "Future info: tensor([[0.1634, 0.0982],\n",
      "        [0.0937, 0.0280],\n",
      "        [0.2265, 0.0471]])\n",
      "\n",
      "True labels:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'direction'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFuture info: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutputs[\u001b[33m'\u001b[39m\u001b[33mfuture_info\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTrue labels:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDirection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdirection\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mComparison: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[\u001b[33m'\u001b[39m\u001b[33mcomparison\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFuture info: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[\u001b[33m'\u001b[39m\u001b[33mfuture_info\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: 'direction'"
     ]
    }
   ],
   "source": [
    "# Prepare a single batch for testing\n",
    "texts = sample_data['news'].tolist()[:3]  # Take 3 examples\n",
    "\n",
    "# Prepare labels - combine direction columns into single labels\n",
    "direction_labels = []\n",
    "for i in range(3):\n",
    "    if sample_data['price_direction_up'].tolist()[i] == 1:\n",
    "        direction_labels.append(1)  # Up\n",
    "    elif sample_data['price_direction_down'].tolist()[i] == 1:\n",
    "        direction_labels.append(0)  # Down\n",
    "    else:\n",
    "        direction_labels.append(2)  # Constant (if you have 3 classes)\n",
    "\n",
    "labels = {\n",
    "    'direction': direction_labels,\n",
    "    'comparison': sample_data['asset_comparision'].tolist()[:3],\n",
    "    'future_info': sample_data['future_information'].tolist()[:3]\n",
    "}\n",
    "\n",
    "# Tokenize\n",
    "inputs = tokenizer(\n",
    "    texts,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "# Move to device\n",
    "input_ids = inputs['input_ids'].to(device)\n",
    "attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "# Test inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, attention_mask)\n",
    "    \n",
    "    # Get predicted classes (argmax of logits)\n",
    "    pred_direction = torch.argmax(outputs['direction'], dim=1)\n",
    "    pred_comparison = torch.argmax(outputs['comparison'], dim=1)\n",
    "    pred_future = torch.argmax(outputs['future_info'], dim=1)\n",
    "\n",
    "print(\"\\nSample predictions (logits):\")\n",
    "print(f\"Direction logits: {outputs['direction']}\")\n",
    "print(f\"Comparison logits: {outputs['comparison']}\")\n",
    "print(f\"Future info logits: {outputs['future_info']}\")\n",
    "\n",
    "print(\"\\nPredicted classes:\")\n",
    "print(f\"Direction: {pred_direction.tolist()}\")\n",
    "print(f\"Comparison: {pred_comparison.tolist()}\")\n",
    "print(f\"Future info: {pred_future.tolist()}\")\n",
    "\n",
    "print(\"\\nTrue labels:\")\n",
    "print(f\"Direction: {labels['direction']}\")\n",
    "print(f\"Comparison: {labels['comparison']}\")\n",
    "print(f\"Future info: {labels['future_info']}\")\n",
    "\n",
    "print(\"\\nAccuracy:\")\n",
    "print(f\"Direction: {(pred_direction.cpu() == torch.tensor(labels['direction'])).sum().item()}/{len(labels['direction'])}\")\n",
    "print(f\"Comparison: {(pred_comparison.cpu() == torch.tensor(labels['comparison'])).sum().item()}/{len(labels['comparison'])}\")\n",
    "print(f\"Future info: {(pred_future.cpu() == torch.tensor(labels['future_info'])).sum().item()}/{len(labels['future_info'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
