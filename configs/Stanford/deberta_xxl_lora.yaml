# DeBERTa-v2-XXLarge (1.5B params) with LoRA Fine-Tuning
# Demonstration that LoRA becomes efficient at larger model scales

# General settings
seed: 42

# Data settings
data:
  file_path: "Stanford/snli_1.0_train.txt"
  data_dir: "Stanford"
  test_size: 0.2
  val_size: 0.1
  pandas_kwargs: {}
  label_map: {'entailment': 0, 'neutral': 1, 'contradiction': 2}

# Weights & Biases configuration
wandb:
  project: "NLP_mini"
  entity: "jojs-it-universitetet-i-k-benhavn"
  run_name: "Stanford_deberta_xxl_lora_r8"
  tags: ['Stanford', 'deberta-xxl', 'lora', 'r=8', 'large-scale']
  log_model: false

# Model settings
model:
  name: "microsoft/deberta-v2-xxlarge"
  model_type: "bert"  # uses same architecture pattern (encoder-only)
  use_lora: true
  freeze_strategy: null  # Not used with LoRA (auto-frozen)
  num_frozen_layers: null
  max_len: 256
  dropout_rate: 0.5
  checkpoint_dir: "checkpoints"
  save_local: false
  
  # LoRA configuration (same as BERT for fair comparison)
  lora:
    r: 8  # LoRA rank 
    lora_alpha: 16  # scaling factor
    lora_dropout: 0.1
    target_modules: ["query_proj", "value_proj"]  # DeBERTa uses different naming
    bias: "none"
    
# Training settings
training:
  batch_size: 4  # reduced for large model (can increase if memory allows)
  num_epochs: 3
  learning_rate: 0.0001  # same as BERT LoRA
  dropout_rate: 0.5
  weight_decay: 0.1
  warmup_ratio: 0.1
  max_grad_norm: 1.0
  early_stopping_patience: 5

