# General settings
seed: 42

# Data settings
data:
  kaggle_dataset: "daittan/gold-commodity-news-and-dimensions"
  file_path: ""  # relative path inside the dataset or empty for default
  data_dir: "data"  # relative to project root
  test_size: 0.2
  val_size: 0.1
  pandas_kwargs: {} # Pandas settings for reading CSV files


# Weights & Biases configuration
wandb:
  project: "NLP_mini"
  entity: "jojs-it-universitetet-i-k-benhavn"
  run_name: "experiment_1"
  tags: ['test']
  log_model: false

# Model settings
model:
  distilbert: "distilbert-base-uncased"
  bert: "bert-base-uncased"
  freeze_strategy: "frozen" #'frozen', 'partial', or 'full'
  num_frozen_layers: 2
  max_len: 512
  dropout_rate: 0.3
  use_lora: false
  checkpoint_dir: "checkpoints"  # relative to project root
  save_local: false  

# Training settings
training:
  batch_size: 4
  num_epochs: 4
  learning_rate: 0.00002
  dropout_rate: 0.3
  weight_decay: 0.01
  warmup_ratio: 0.1
  max_grad_norm: 1.0
  early_stopping_patience: 3

Lora:
  r: 8  # LoRA rank 
  lora_alpha: 16  
  lora_dropout: 0.1  
  target_modules: ["query", "value"]  # which attention weight matrices to adapt
  bias: "none"  # 'none', 'all' or 'lora_only'
  task_type: "SEQ_CLS" 
  inference_mode: False
  modules_to_save: "classifier"
